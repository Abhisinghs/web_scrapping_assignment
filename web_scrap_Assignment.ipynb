{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f9936-d104-4543-b30f-7c81a5690424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer_1\n",
    "\n",
    "In the context of data science, web scraping is a way of collecting data from a website by means of a\n",
    "script that reads the content from the pages on the website and then stores the data in a database or\n",
    "spreadsheet. This is a fast and easy way to gather data from a website, but it comes at a price.\n",
    "\n",
    "#Applications of web scraping tools\n",
    "\n",
    "Monitoring e-commerce prices.\n",
    "Finding opportunities for investment.\n",
    "Analyzing social media web data.\n",
    "Applying machine learning techniques.\n",
    "Gathering web data automatically.\n",
    "Researching new concepts in a field.\n",
    "Extracting contact information.\n",
    "Monitoring news sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6d252-91d0-4a09-8521-2354c964f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer_2\n",
    "\n",
    "we use different method in web scrapping\n",
    "\n",
    "1.we use GET and POST method to get the data from user and but both have different feature POST  is more secure\n",
    "2.render_template() #this method is used show the html file front of the user\n",
    "3.bs(website_page,\"html.parser\")  #this method is used to beautify the data it set data as indentation\n",
    "4.find_all()  #this method is used to find the data from the html division tag in specific class\n",
    "5.we use all database method to store the data like insert_one() ,insert_many(),find_one(),find_many()\n",
    "6.we use all flask method to create api that connect two different system .\n",
    "7.we use logging method to log the file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77065967-9d42-4e14-bf0c-915930e90b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer_3\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup,\n",
    "i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used \n",
    "to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "Beautiful Soup was started by Leonard Richardson, who continues to contribute to the project,\n",
    "and is additionally supported by Tidelift, a paid subscription to open-source maintenance.\n",
    "\n",
    "\n",
    "It is usually used in conjunction with urllib or the requests package in python in order to extract required\n",
    "information from a website represented by it’s url otherwise also known as Web-Scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefc53f-5e07-414d-81df-09664dc3415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer_4\n",
    "\n",
    "flask is a pythonic library which used to create api that are connect two different system or different platform.\n",
    "Flask is a lightweight framework to build websites. We’ll use this to parse our collected\n",
    "data and display it as HTML in a new HTML file.\n",
    "\n",
    "The requests module allows us to send http requests to the website we want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b84e3a-745a-4a4a-b153-e6a472c35480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app=Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")              #App Routing means mapping the URLs to a specific function that will\n",
    "def hello_world():             #handle the logic for that URL\n",
    "    return \"hello world!\"\n",
    "\n",
    "if __name__=\"__main__\":\n",
    "    app.run(host=\"0.0.0.0\")\n",
    "    \n",
    "#basically we create simple program but render_template() The function simply returns something here it calls the\n",
    "# function render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f93f23-b286-4707-b6dd-b8c603bdf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer_5\n",
    "\n",
    "AWS is a cloud platform in which we will host the application and when application up and running  all time so\n",
    "user can use this application through AWS cloud platform .\n",
    "\n",
    "AWS provide many services but only we use two services in web scrapping project\n",
    "\n",
    "1.Code pipeline\n",
    "\n",
    "AWS CodePipeline is a continuous delivery service you can use to model, visualize,\n",
    "and automate the steps required to release your software. You can quickly model and configure\n",
    "the different stages of a software release process. CodePipeline automates the steps required to\n",
    "release your software changes continuously.\n",
    "\n",
    "\n",
    "2.Beanstak\n",
    "\n",
    "Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your\n",
    "code and Elastic Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, \n",
    "and auto scaling to application health monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
